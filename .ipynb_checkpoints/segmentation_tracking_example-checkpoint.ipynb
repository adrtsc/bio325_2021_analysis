{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286643f3-d9f2-4c61-9944-221e7fb19c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "from lca.ndt.segmentation import segment_nuclei_cellpose_2DT\n",
    "from lca.ndt.LapTracker import LapTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cf5f57-ad87-474e-90fd-892af513edc6",
   "metadata": {},
   "source": [
    "# Object segmentation with cellpose\n",
    "\n",
    "In this notebook, we will try to segment cells/nuclei in microscopy images. We will use a deep-learning based approach to segment the objects in this course (as opposed to more classical approaches). The largest disadvantage of deep-learning based approaches is that they often require training data that is hard to produce. In this course, we will circumvent this by using cellpose (http://www.cellpose.org/). Cellpose is a generalist deep-learning based approach that performs very well out-of-the-box to segment nuclei and cytoplasm of cells in images. \n",
    "\n",
    "\n",
    "### Nuclei segmentation\n",
    "Let's start by loading some of the images that you have produced into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3239261c-bbf8-4bbe-b76c-5df4d1fdd949",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = Path(r'Z:\\20210930_dummy\\hdf5')\n",
    "site = 1\n",
    "file = h5py.File(img_path.joinpath('site_%04d.hdf5' % site), \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe565a0-29be-43d7-a108-e36ea41205c7",
   "metadata": {},
   "source": [
    "Now let's look at the data in napari. Cellpose has a plugin for napari that let's you use a graphical user interface to do segmentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acfecb21-dcb3-46c4-80e3-c24aa801146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation errors in config file(s).\n",
      "The following fields have been reset to the default value:\n",
      "\n",
      "plugins -> call_order\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new log file\n",
      "2021-10-20 11:10:51,997 [INFO] WRITING LOG OUTPUT TO C:\\Users\\Adrian\\.cellpose\\run.log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'nuclei_img' at 0x2033d9343d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-20 11:10:53,494 [ERROR] Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Adrian\\miniconda3\\envs\\bio325_2021\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 431, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\Adrian\\miniconda3\\envs\\bio325_2021\\lib\\site-packages\\jupyter_client\\threaded.py\", line 121, in _handle_recv\n",
      "    msg_list = self.ioloop._asyncio_event_loop.run_until_complete(get_msg(future_msg))\n",
      "  File \"C:\\Users\\Adrian\\miniconda3\\envs\\bio325_2021\\lib\\asyncio\\base_events.py\", line 618, in run_until_complete\n",
      "    self._check_running()\n",
      "  File \"C:\\Users\\Adrian\\miniconda3\\envs\\bio325_2021\\lib\\asyncio\\base_events.py\", line 580, in _check_running\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Cannot run the event loop while another loop is running\n"
     ]
    }
   ],
   "source": [
    "nuclei_img = file['intensity_images/sdcDAPIxmRFPm'][0,:,:]\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(nuclei_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caf3df7-f16b-455d-af94-3d57c64caafe",
   "metadata": {},
   "source": [
    "In the IT introduction we already used a plugin in napari. You can open plugins from the menu bar under Plugins. There you should see \"cellpose-napari: cellpose\".\n",
    "\n",
    "Try to play around with the settings to get a decent segmentation of the nuclei. \n",
    "IMPORTANT: keep the \"resample dynamics\" box unticked. If you use this option it will take a very long time to generate the segmentation.\n",
    "\n",
    "### Cell segmentation\n",
    "\n",
    "If you are happy with your nuclei segmentation, try to load an image of the membrane marker and see if you can generate a segmentation of the cells as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5283d9-8817-4f70-985e-d92f5406e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try cell segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b04c90-8f06-4a3d-ab4d-2f8141e12d1f",
   "metadata": {},
   "source": [
    "# Segmentation and object tracking with 2DT data \n",
    "Since the data you have generated are movies, we can think of them as 3D arrays in which the third dimension is time (2DT). We can also do segmentations for a 2DT array directly instead of only a single image. Let's start by loading a 3D image stack. This stack will have the dimensions (t, y, x). Run the next cell and look at the images in napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f23b1a5f-209e-4a65-b18f-cf9cbe344900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-20 11:10:57,982 [INFO] >>>> using CPU\n",
      "2021-10-20 11:11:01,551 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2021-10-20 11:11:07,545 [INFO] >>>> TOTAL TIME 5.99 sec\n",
      "2021-10-20 11:11:07,657 [INFO] >>>> using CPU\n",
      "2021-10-20 11:11:11,157 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2021-10-20 11:11:16,988 [INFO] >>>> TOTAL TIME 5.83 sec\n",
      "2021-10-20 11:11:17,101 [INFO] >>>> using CPU\n",
      "2021-10-20 11:11:20,701 [INFO] ~~~ FINDING MASKS ~~~\n",
      "2021-10-20 11:11:26,598 [INFO] >>>> TOTAL TIME 5.90 sec\n"
     ]
    }
   ],
   "source": [
    "nuclei_img_2DT = file['intensity_images/sdcDAPIxmRFPm'][0:5,:,:]\n",
    "viewer.add_image(nuclei_img_2DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a19117-cba5-46fb-82d6-48ad68b3d85a",
   "metadata": {},
   "source": [
    "The next cell will create cellpose segmentations for the nuclei at each timepoint of the 3D image and add it to napari as labels. It is doing the same thing as the cellpose plugin for napari, just without a graphical user interface. Make sure that you adapt the diameter with the diameter that worked for you during testing with the cellpose plugin for napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65359fcd-956e-4283-ad99-db8ed22f23bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'nuclei_2DT' at 0x2033e54bfd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuclei_2DT = segment_nuclei_cellpose_2DT(nuclei_img_2DT, diameter=150, resample=False)\n",
    "viewer.add_labels(nuclei_2DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a256b90-ef5a-4687-acc9-9de61c40b6c0",
   "metadata": {},
   "source": [
    "As you can see we now have labels for each timepoint. As humans, it is easy for us to see which labels correspond to the same nucleus in the image over time. But the computer doesn't have a clue so far, so we need to tell it somehow which labels belong together over time. This process is called \"object tracking\". There is a lot of object tracking algorithms out there. Today we will use a so called \"linear assignment problem\" tracker that is based on the following publication: https://www.nature.com/articles/nmeth.1237. \n",
    "\n",
    "The following cell will perform the tracking for you. As you know by now, napari has multiple layer \"types\" (e.g. image layers and label layers). There is also a layer type called tracks layer. This is a very handy way to visualize tracking results. The results of the tracking will be added to your napari viewer on a tracks layer. Run the following cell and see what happens on the napari viewer. Are you happy with the tracking? If not, try to play with the parameters of the tracker (max_distance, time_window, max_split_distance, max_gap_closing_distance) and run the cell again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0be49ce6-2669-4581-8471-499400c351ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = LapTracker(max_distance=50, time_window=3, max_split_distance=100, max_gap_closing_distance=100)\n",
    "tracked_labels, tracks = tracker.track_label_images(nuclei_2DT)\n",
    "viewer.add_tracks(tracks[['track_id', 'timepoint', 'centroid-0', 'centroid-1']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
